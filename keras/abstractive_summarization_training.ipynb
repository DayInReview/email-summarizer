{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "extractive_summarization_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FfEXqAs_4eC",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/sandeepbhogaraju/text-summarization-with-seq2seq-model/notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq-505xSfyj1",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NCS9p-Hfyj3",
        "colab_type": "text"
      },
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4qQu5YFfyj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "summary = pd.read_csv('data/news_summary.csv', encoding='iso-8859-1')\n",
        "summary_more = pd.read_csv('data/news_summary_more.csv', encoding='iso-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0nn8fWOfyj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre1 = summary.iloc[:, 0:6].copy()\n",
        "pre2 = summary_more.iloc[:, 0:2].copy()\n",
        "\n",
        "pre1['text'] = pre1['text'].str.cat(pre1['ctext'], sep = \" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49vUL6LIfykF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "03bb50cc-a533-4f77-9d2d-5cf595af343c"
      },
      "source": [
        "pre = pd.DataFrame()\n",
        "pre['text'] = pd.concat([pre1['text'], pre2['text']], ignore_index=True)\n",
        "pre['summary'] = pd.concat([pre1['headlines'],pre2['headlines']],ignore_index = True)\n",
        "pre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Administration of Union Territory Daman an...</td>\n",
              "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
              "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
              "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
              "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
              "      <td>Hotel staff to get training to spot signs of s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102910</th>\n",
              "      <td>A CRPF jawan was on Tuesday axed to death with...</td>\n",
              "      <td>CRPF jawan axed to death by Maoists in Chhatti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102911</th>\n",
              "      <td>'Uff Yeh', the first song from the Sonakshi Si...</td>\n",
              "      <td>First song from Sonakshi Sinha's 'Noor' titled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102912</th>\n",
              "      <td>According to reports, a new version of the 199...</td>\n",
              "      <td>'The Matrix' film to get a reboot: Reports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102913</th>\n",
              "      <td>A new music video shows rapper Snoop Dogg aimi...</td>\n",
              "      <td>Snoop Dogg aims gun at clown dressed as Trump ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102914</th>\n",
              "      <td>Madhesi Morcha, an alliance of seven political...</td>\n",
              "      <td>Madhesi Morcha withdraws support to Nepalese g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102915 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text                                            summary\n",
              "0       The Administration of Union Territory Daman an...  Daman & Diu revokes mandatory Rakshabandhan in...\n",
              "1       Malaika Arora slammed an Instagram user who tr...  Malaika slams user who trolled her for 'divorc...\n",
              "2       The Indira Gandhi Institute of Medical Science...  'Virgin' now corrected to 'Unmarried' in IGIMS...\n",
              "3       Lashkar-e-Taiba's Kashmir commander Abu Dujana...  Aaj aapne pakad liya: LeT man Dujana before be...\n",
              "4       Hotels in Maharashtra will train their staff t...  Hotel staff to get training to spot signs of s...\n",
              "...                                                   ...                                                ...\n",
              "102910  A CRPF jawan was on Tuesday axed to death with...  CRPF jawan axed to death by Maoists in Chhatti...\n",
              "102911  'Uff Yeh', the first song from the Sonakshi Si...  First song from Sonakshi Sinha's 'Noor' titled...\n",
              "102912  According to reports, a new version of the 199...         'The Matrix' film to get a reboot: Reports\n",
              "102913  A new music video shows rapper Snoop Dogg aimi...  Snoop Dogg aims gun at clown dressed as Trump ...\n",
              "102914  Madhesi Morcha, an alliance of seven political...  Madhesi Morcha withdraws support to Nepalese g...\n",
              "\n",
              "[102915 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmH1IIiHfykI",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpYM8CN3fykJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def text_strip(column):\n",
        "    for row in column:\n",
        "                \n",
        "        row=re.sub(\"(\\\\t)\", ' ', str(row)).lower() #remove escape charecters\n",
        "        row=re.sub(\"(\\\\r)\", ' ', str(row)).lower() \n",
        "        row=re.sub(\"(\\\\n)\", ' ', str(row)).lower()\n",
        "        \n",
        "        row=re.sub(\"(__+)\", ' ', str(row)).lower()   #remove _ if it occors more than one time consecutively\n",
        "        row=re.sub(\"(--+)\", ' ', str(row)).lower()   #remove - if it occors more than one time consecutively\n",
        "        row=re.sub(\"(~~+)\", ' ', str(row)).lower()   #remove ~ if it occors more than one time consecutively\n",
        "        row=re.sub(\"(\\+\\++)\", ' ', str(row)).lower()   #remove + if it occors more than one time consecutively\n",
        "        row=re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()   #remove . if it occors more than one time consecutively\n",
        "        \n",
        "        row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower() #remove <>()|&©ø\"',;?~*!\n",
        "        \n",
        "        row=re.sub(\"(mailto:)\", ' ', str(row)).lower() #remove mailto:\n",
        "        row=re.sub(r\"(\\\\x9\\d)\", ' ', str(row)).lower() #remove \\x9* in text\n",
        "        row=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(row)).lower() #replace INC nums to INC_NUM\n",
        "        row=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(row)).lower() #replace CM# and CHG# to CM_NUM\n",
        "        \n",
        "        \n",
        "        row=re.sub(\"(\\.\\s+)\", ' ', str(row)).lower() #remove full stop at end of words(not between)\n",
        "        row=re.sub(\"(\\-\\s+)\", ' ', str(row)).lower() #remove - at end of words(not between)\n",
        "        row=re.sub(\"(\\:\\s+)\", ' ', str(row)).lower() #remove : at end of words(not between)\n",
        "        \n",
        "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
        "        \n",
        "        # Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n",
        "        try:\n",
        "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
        "            repl_url = url.group(3)\n",
        "            row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(row))\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "\n",
        "        \n",
        "        row = re.sub(\"(\\s+)\",' ',str(row)).lower() # Remove multiple spaces\n",
        "        \n",
        "        # Should always be last\n",
        "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() # Remove any single charecters hanging between 2 spaces\n",
        "\n",
        "        \n",
        "        \n",
        "        yield row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyeDGoMJfykM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text_strip(pre['text'])\n",
        "summary = text_strip(pre['summary'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TPPEEUWfykP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e30b1da6-da18-4fa0-90c7-84e56c8e306a"
      },
      "source": [
        "import spacy\n",
        "from time import time\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
        "\n",
        "# Text Cleaning\n",
        "t = time()\n",
        "\n",
        "text = [str(doc) for doc in nlp.pipe(text, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "print(f'Time to clean text: {round((time() - t) / 60, 2)} mins')\n",
        "\n",
        "# Summary Cleaning\n",
        "t = time()\n",
        "\n",
        "summary = [str(doc) for doc in nlp.pipe(summary, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "print(f'Time to clean summary: {round((time() - t) / 60, 2)} mins')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean text: 4.0 mins\n",
            "Time to clean summary: 0.76 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T02IFsMfykU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "c853dddb-a774-44b6-915e-b04d166551d0"
      },
      "source": [
        "text[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'malaika arora slammed an instagram user who trolled her for divorcing rich man and having fun with the alimony her life now is all about wearing short clothes going to gym or salon enjoying vacation the user commented malaika responded you certainly got to get your damn facts right before spewing sh on me when you know nothing about me from her special numbers to tv appearances bollywood actor malaika arora khan has managed to carve her own identity the actor who made her debut in the hindi film industry with the blockbuster debut opposite shah rukh khan in chaiyya chaiyya from dil se 1998 is still remembered for the song however for trolls she is woman first and what matters right now is that she divorced rich man on wednesday malaika arora shared gorgeous picture of herself on instagram and follower decided to troll her for using her alumni read alimony money to wear short clothes and going to gym or salon little did he/she know that the munni badnam star would reply with the perfect comeback take look at the interaction super excited to be affiliated with khanna jewellers @khannajewellerskj as their brand ambassador crafted to perfection their stunning statement jewellery is must have for every jewellery lover #khannajewellers #maksquad #hair @hairbypriyanka #stylist @manekaharisinghani #manager @ektakauroberoi #mua @subbu28 #photographer @prasdnaik post shared by malaika arora khan @malaikaarorakhanofficial on aug 2017 at 6:20am pdt then malaika decided to reply the entire conversation only proves that no matter if woman is successful she will be attacked the moment she decides to step out of bounds the society decided for her apart from being successful woman who lives life on her own terms malaika has literally played all the roles traditionally prescribed for woman she married quite early had son and raised him and was always around with the khandan but then she got divorced and alimony is the taunt being thrown at her the details of the alimony are only known to malaika her husband arbaaz khan and perhaps the family the couple has handled the divorce with the utmost dignity but we can vouch for the fact that she did not need an alimony to buy clothes short or not her choice go on vacations and enjoy her life if anything she is as successful if not more than her ex-husband.what happened between arbaaz and malaika is their personal concern but to claim that malaika married and then divorced arbaaz for money doesn hold water for those who do not agree please get course in feminism and for others here playlist of some of her most popular songs follow @htshowbiz for more'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlTgt6ZlfykZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d418d867-1456-4346-dda9-0027c87a4a58"
      },
      "source": [
        "summary[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'malaika slams user who trolled her for divorcing rich man '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWNcuMzpfykb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "cleaned_text = np.array(text)\n",
        "cleaned_summary = np.array(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0wp7SxXfyke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned = pd.DataFrame({'text' : cleaned_text, 'summary' : cleaned_summary})\n",
        "cleaned['summary'] = cleaned['summary'].apply(lambda x : 'sostok '+ x + ' eostok')\n",
        "cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUKRyp9ofykk",
        "colab_type": "text"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7A6BquAfykl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_text_len = 250\n",
        "max_summary_len = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z-IDdVXfykr",
        "colab_type": "text"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBBxsp4efykr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(cleaned['text']), np.array(cleaned['summary']), test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP3tf5U_fykw",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Un3oRakfykx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_tokenizer = Tokenizer()\n",
        "X_tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpc1r6Ghfyk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_num_words = len(X_tokenizer.word_index) + 1\n",
        "X_num_rare_words = 0\n",
        "\n",
        "thresh = 4\n",
        "for key, value in X_tokenizer.word_counts.items():\n",
        "    if(value < thresh):\n",
        "        X_num_rare_words += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDbhymrOfyk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRVHoZgmfyk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_num_words = len(y_tokenizer.word_index) + 1\n",
        "y_num_rare_words = 0\n",
        "\n",
        "thresh = 6\n",
        "for key, value in y_tokenizer.word_counts.items():\n",
        "    if(value < thresh):\n",
        "        y_num_rare_words += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3B_OdFcfylF",
        "colab_type": "text"
      },
      "source": [
        "### X Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJTdcgvdfylG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tokenizer = Tokenizer(num_words=X_num_words-X_num_rare_words)\n",
        "X_tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP7TlVszfylJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_tokenizer.texts_to_sequences(X_train)\n",
        "X_test = X_tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDHFEdtGfylM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pad_sequences(X_train, maxlen=max_text_len, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_text_len, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYbFOXgWfylP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_voc = X_tokenizer.num_words + 1\n",
        "X_voc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqzJrXjUfylS",
        "colab_type": "text"
      },
      "source": [
        "### Y Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjmqCqY1fylS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_tokenizer = Tokenizer(num_words=y_num_words-y_num_rare_words)\n",
        "y_tokenizer.fit_on_texts(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjRIFb56fylW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_tokenizer.texts_to_sequences(y_train)\n",
        "y_test = y_tokenizer.texts_to_sequences(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpQgkQMJfylZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J-lSFhqfylc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_voc = y_tokenizer.num_words + 1\n",
        "y_voc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR-V7eh_fylg",
        "colab_type": "text"
      },
      "source": [
        "## Remove Blanks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtcPvDUBfylh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = list()\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "    count = 0\n",
        "    for j in y_train[i]:\n",
        "        if j != 0:\n",
        "            count += 1\n",
        "    if count == 2:\n",
        "        idx.append(i)\n",
        "\n",
        "y_train = np.delete(y_train, idx, axis=0)\n",
        "X_train = np.delete(X_train, idx, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfogYRVbfylj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = list()\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    count = 0\n",
        "    for j in y_test[i]:\n",
        "        if j != 0:\n",
        "            count += 1\n",
        "    if count == 2:\n",
        "        idx.append(i)\n",
        "\n",
        "y_test = np.delete(y_test, idx, axis=0)\n",
        "X_test = np.delete(X_test, idx, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itJVj-XIfyln",
        "colab_type": "text"
      },
      "source": [
        "## Create Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-KKGksmfylo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim = 200\n",
        "\n",
        "## Encoder ##\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "# Embedding layer\n",
        "encoder_emb = Embedding(X_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
        "\n",
        "# LSTM 1\n",
        "encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(encoder_emb)\n",
        "\n",
        "# LSTM 2\n",
        "encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# LSTM 3\n",
        "encoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_output3, state_h, state_c = encoder_lstm3(encoder_output2)\n",
        "\n",
        "## Decoder ##\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "# Embedding layer\n",
        "decoder_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
        "decoder_emb = decoder_emb_layer(decoder_inputs)\n",
        "\n",
        "# LSTM\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
        "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(decoder_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "# Dense Layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "## Model ##\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT-5zTavfylq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CfN9_C6APn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfOUpbo8fyl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit([X_train, y_train[:, :-1]],\n",
        "                    y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
        "                    epochs=50,\n",
        "                    callbacks=[es],\n",
        "                    batch_size=128,\n",
        "                    validation_data=([X_test, y_test[:, :-1]],\n",
        "                    y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:, 1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvJzoSaTfymG",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJBZuzWufymJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I004pgzm8Wjx",
        "colab_type": "text"
      },
      "source": [
        "# Inferencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJbzSAZ28YMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index = y_tokenizer.index_word\n",
        "reverse_source_word_index = X_tokenizer.index_word\n",
        "target_word_index = y_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Y1Eo9e8kLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_output3, state_h, state_c])\n",
        "\n",
        "# Decoder\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))\n",
        "\n",
        "# Embeddings\n",
        "decoder_emb2 = decoder_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF2le4i5_FEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EDEhtj7_N3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khedR4zD_VM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,5):\n",
        "    print(\"Review:\", seq2text(X_train[i]))\n",
        "    print(\"Original summary:\", seq2summary(y_train[i]))\n",
        "    print(\"Predicted summary:\", decode_sequence(X_train[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}